{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据读取\n",
    "- DataFrame常用属性与方法\n",
    "- 基础时间数据处理方法\n",
    "- 分组聚合的原理与方法\n",
    "- 透视表与交叉表的制作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读写不同数据源的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据库数据的读写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 需使用 pandas 和 SQLAlchemy（建立对应数据库的连接） 库\n",
    "- SQLAlchemy配合相应数据库的python连接工具，MySQL需安装mysqlclient或者pymysql库【命令行窗口==》conda info -e==》查看环境，记住想安装库到相应环境的环境名==》 activate 环境名（要安装pymysql的环境）==》 pip intall pymysql】，oracle需安装cx_oracle库\n",
    "- 使用create_engine函数建立一个数据库连接"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据库数据的读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- read_sql_table ==> 读取数据库的一个表格，不能实现查询操作\n",
    "- read_sql_query ==> 只能实现查询操作，不能读取数据库的某个表\n",
    "- read_sql ========> 两者的综合\n",
    "\n",
    "``` python\n",
    "pd.read_sql_table(table_name, con, schema=None, index_col=None, coerce_float=True, parse_dates=None, columns=None, chunksize=None)\n",
    "pd.read_sql_query(sql, con, index_col=None, coerce_float=True, params=None, parse_dates=None, chunksize=None)\n",
    "pd.read_sql(sql, con, index_col=None, coerce_float=True, params=None, parse_dates=None, columns=None, chunksize=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine(mysql+pymysql://root:***@127.0.0.1:3306/testdb?charset=utf8)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "# 创建MySQL连接器，用户名root，密码1234\n",
    "# 地址127.0.0.1 ， 数据库名称 testdb，编码UTF-8\n",
    "engine = create_engine('mysql+pymysql://root:123000@127.0.0.1:3306/testdb?charset=utf8')\n",
    "print(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create_engine的输入参数格式（MySQL和oracle）：\n",
    "    - `数据库产品名+连接工具名+://用户名:密码@数据库IP地址:数据库端口号/数据库名称?charset=数据库数据编码`\n",
    "- 三个读取函数的参数说明\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>参数</td>\n",
    "        <td>说明</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>sql或table_name</td>\n",
    "        <td>string——读取的数据库的表明或sql语句</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>con</td>\n",
    "        <td>数据库连接——数据库的连接信息</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>index_col</td>\n",
    "        <td>int、sequence、False——设定的列作为行名，如果是一个数列，是多重索引</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>coerce_float</td>\n",
    "        <td>boolean——将数据库的decimal类型数据转换为pandas中的float64类型</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>columns</td>\n",
    "        <td>list——读取数据的列名</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据库服务启动\n",
    "    - net start mysql\n",
    "    - mysql -u root -p \n",
    "- 设置密码\n",
    "    - SET PASSWORD FOR 'root'@'localhost' ='123000';\n",
    "- 创建数据库\n",
    "    - CREATE DATABASE testdb;\n",
    "    - use testdb;\n",
    "- 运行sql代码：\n",
    "    - source: E:\\Program Files\\Mysql\\mysql-8.0.11-winx64\\Data\\testdb\\meal_order_detail1.sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 错误 -- sqlalchemy.exc.InternalError: (pymysql.err.InternalError) (1193, \"Unknown system variable 'tx_isolation'\")\n",
    "- 在sqlalchemy包文件所在目录中找到base.py，打开，将tx_isolation改为transaction_isolation\n",
    "- ![2018-07-22_164619.png](https://i.loli.net/2018/07/22/5b5444a760e76.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testdb数据库数据表清单为: \n",
      "      Tables_in_testdb\n",
      "0  meal_order_detail1\n",
      "1  meal_order_detail2\n",
      "2  meal_order_detail3\n"
     ]
    }
   ],
   "source": [
    "## 使用read_sql_query查看tesdb中的数据表数目\n",
    "formlist = pd.read_sql_query('show tables', con = engine)\n",
    "print('testdb数据库数据表清单为:','\\n',formlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用read_sql_table读取订单详情表的长度为: 2779\n"
     ]
    }
   ],
   "source": [
    "## 使用read_sql_table读取订单详情表\n",
    "detail1 = pd.read_sql_table('meal_order_detail1',con=engine)\n",
    "print('使用read_sql_table读取订单详情表的长度为:',len(detail1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用read_sql函数+sql语句读取的订单详情表长度为: 3647\n",
      "使用read_sql函数+表格名称读取的订单详情表长度为: 3611\n"
     ]
    }
   ],
   "source": [
    "## 使用read_sql读取订单详情表\n",
    "\n",
    "detail2 = pd.read_sql('select * from meal_order_detail2',con=engine)\n",
    "print('使用read_sql函数+sql语句读取的订单详情表长度为:',len(detail2))\n",
    "detail3 = pd.read_sql('meal_order_detail3',con=engine)\n",
    "print('使用read_sql函数+表格名称读取的订单详情表长度为:', len(detail3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  数据库数据的写入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同样需要SQLAlchemy库的create_engine的连接\n",
    "- pd.DataFrame.to_sql(self, name, con, flavor=None, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None)\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>参数</td>\n",
    "        <td>说明</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>name</td>\n",
    "        <td>string——数据库的表名</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>con</td>\n",
    "        <td>数据库连接——数据库的连接信息</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>if_exists</td>\n",
    "        <td>fail、replace、append——分别表示 表明存在则不写入，将原数据库删除再重新创建，原数据库基础上追加数据</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>index</td>\n",
    "        <td>boolean——是否将行索引作为数据传入数据库</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>index_lable</td>\n",
    "        <td>string或sequence——是否引用索引名称，若index为true，则此参数为None，使用默认名称，如果为多重索引，须使用sequence形式</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>dtype</td>\n",
    "        <td>dict——写入的数据类型，列名为key，数据格式为values</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新增一个表格后testdb数据库数据表清单为： \n",
      "      Tables_in_testdb\n",
      "0  meal_order_detail1\n",
      "1  meal_order_detail2\n",
      "2  meal_order_detail3\n",
      "3               test1\n"
     ]
    }
   ],
   "source": [
    "## 使用to_sql存储orderData\n",
    "detail1.to_sql('test1',con=engine,index=False,if_exists='replace')\n",
    "## 使用read_sql读取test表\n",
    "formlist1 = pd.read_sql_query('show tables', con=engine)\n",
    "print('新增一个表格后testdb数据库数据表清单为：','\\n',formlist1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读写文本文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pd.read_table(filepath_or_buffer, sep='\\t', header='infer', names=None, index_col=None, dtype=None, engine=None, nrows=None, encoding=None)\n",
    "- pd.read_csv(filepath_or_buffer, sep=',', header='infer', names=None, index_col=None, dtype=None, engine=None, nrows=None, encoding=None)\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>参数</td>\n",
    "        <td>说明</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>filepath</td>\n",
    "        <td>string——路径</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>sep</td>\n",
    "        <td>string——分隔符，read_csv默认为“,”，read_table默认为“Tab”</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>names</td>\n",
    "        <td>array——列名</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>index_col</td>\n",
    "        <td>int、False或sequence——索引列的位置，sequence为多重索引</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>engine</td>\n",
    "        <td>c或python——数据解析引擎，默认为C</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>dtype</td>\n",
    "        <td>dict——写入的数据类型，列名为key，数据格式为values</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>nrows</td>\n",
    "        <td>int——读取前n行</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用read_table读取的订单信息表的长度为： 945\n"
     ]
    }
   ],
   "source": [
    "## 使用read_table读取订单信息表\n",
    "order = pd.read_table('./pandas/data/meal_order_info.csv', sep = ',',encoding = 'gbk')\n",
    "print('使用read_table读取的订单信息表的长度为：',len(order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用read_csv读取的订单信息表的长度为： 945\n"
     ]
    }
   ],
   "source": [
    "## 使用read_csv读取订单信息表\n",
    "order1 = pd.read_csv('./pandas/data/meal_order_info.csv', encoding = 'gbk')\n",
    "print('使用read_csv读取的订单信息表的长度为：',len(order1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 读取菜品订单信息表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分隔符为;时订单信息表为：\n",
      "   info_id,\"emp_id\",\"number_consumers\",\"mode\",\"dining_table_id\",\"dining_table_name\",\"expenditure\",\"dishes_count\",\"accounts_payable\",\"use_start_time\",\"check_closed\",\"lock_time\",\"cashier_id\",\"pc_id\",\"order_number\",\"org_id\",\"print_doc_bill_num\",\"lock_table_info\",\"order_status\",\"phone\",\"name\"\n",
      "0  417,1442,4,NA,1501,1022,165,5,165,\"2016/8/1 11...                                                                                                                                                                                                                                            \n",
      "1  301,1095,3,NA,1430,1031,321,6,321,\"2016/8/1 11...                                                                                                                                                                                                                                            \n",
      "2  413,1147,6,NA,1488,1009,854,15,854,\"2016/8/1 1...                                                                                                                                                                                                                                            \n",
      "3  415,1166,4,NA,1502,1023,466,10,466,\"2016/8/1 1...                                                                                                                                                                                                                                            \n",
      "4  392,1094,10,NA,1499,1020,704,24,704,\"2016/8/1 ...                                                                                                                                                                                                                                            \n",
      "5  381,1243,4,NA,1487,1008,239,7,239,\"2016/8/1 13...                                                                                                                                                                                                                                            \n",
      "6  429,1452,4,NA,1501,1022,699,15,699,\"2016/8/1 1...                                                                                                                                                                                                                                            \n",
      "7  433,1109,8,NA,1490,1011,511,14,511,\"2016/8/1 1...                                                                                                                                                                                                                                            \n",
      "8  569,1143,6,NA,1488,1009,326,9,326,\"2016/8/1 17...                                                                                                                                                                                                                                            \n",
      "9  655,1268,8,NA,1492,1013,263,10,263,\"2016/8/1 1...                                                                                                                                                                                                                                            \n"
     ]
    }
   ],
   "source": [
    "## 使用read_table读取菜品订单信息表,sep = ';'\n",
    "order2 = pd.read_table('./pandas/data/meal_order_info.csv', sep = ';',encoding = 'gbk')\n",
    "print('分隔符为;时订单信息表为：\\n',order2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单信息表为： \n",
      "         0       1                 2     3                4   \\\n",
      "0  info_id  emp_id  number_consumers  mode  dining_table_id   \n",
      "1      417    1442                 4   NaN             1501   \n",
      "2      301    1095                 3   NaN             1430   \n",
      "3      413    1147                 6   NaN             1488   \n",
      "4      415    1166                 4   NaN             1502   \n",
      "\n",
      "                  5            6             7                 8   \\\n",
      "0  dining_table_name  expenditure  dishes_count  accounts_payable   \n",
      "1               1022          165             5               165   \n",
      "2               1031          321             6               321   \n",
      "3               1009          854            15               854   \n",
      "4               1023          466            10               466   \n",
      "\n",
      "                  9   ...                  11          12     13  \\\n",
      "0     use_start_time  ...           lock_time  cashier_id  pc_id   \n",
      "1  2016/8/1 11:05:36  ...   2016/8/1 11:11:46         NaN    NaN   \n",
      "2  2016/8/1 11:15:57  ...   2016/8/1 11:31:55         NaN    NaN   \n",
      "3  2016/8/1 12:42:52  ...   2016/8/1 12:54:37         NaN    NaN   \n",
      "4  2016/8/1 12:51:38  ...   2016/8/1 13:08:20         NaN    NaN   \n",
      "\n",
      "             14      15                  16               17            18  \\\n",
      "0  order_number  org_id  print_doc_bill_num  lock_table_info  order_status   \n",
      "1           NaN     330                 NaN              NaN             1   \n",
      "2           NaN     328                 NaN              NaN             1   \n",
      "3           NaN     330                 NaN              NaN             1   \n",
      "4           NaN     330                 NaN              NaN             1   \n",
      "\n",
      "            19    20  \n",
      "0        phone  name  \n",
      "1  18688880641   苗宇怡  \n",
      "2  18688880174    赵颖  \n",
      "3  18688880276   徐毅凡  \n",
      "4  18688880231   张大鹏  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "## 使用read_csv读取菜品订单信息表,header=None\n",
    "order3 = pd.read_csv('./pandas/data/meal_order_info.csv', sep = ',',header = None,encoding = 'gbk')\n",
    "print('订单信息表为：','\\n',order3[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xc3 in position 0: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens (pandas\\_libs\\parsers.c:14858)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype (pandas\\_libs\\parsers.c:17119)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert (pandas\\_libs\\parsers.c:17347)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8 (pandas\\_libs\\parsers.c:23041)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xc3 in position 0: invalid continuation byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-0a08a32493e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## 使用utf-8解析菜品订单信息表\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0morder4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./pandas/data/meal_order_info.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\Python_36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\Python_36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\Python_36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1003\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1005\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'as_recarray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\Python_36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1746\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1747\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1748\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1749\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1750\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read (pandas\\_libs\\parsers.c:10862)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory (pandas\\_libs\\parsers.c:11138)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows (pandas\\_libs\\parsers.c:12175)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data (pandas\\_libs\\parsers.c:14136)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens (pandas\\_libs\\parsers.c:14972)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype (pandas\\_libs\\parsers.c:17119)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert (pandas\\_libs\\parsers.c:17347)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8 (pandas\\_libs\\parsers.c:23041)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xc3 in position 0: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "## 使用utf-8解析菜品订单信息表\n",
    "order4 = pd.read_csv('./pandas/data/meal_order_info.csv', sep = ',',encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- pd.DataFrame.to_csv(path_or_buf=None, sep=',', na_rep='', columns=None, header=True, index=True, index_label=None, mode='w', encoding=None)\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>参数</td>\n",
    "        <td>说明</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>path_or_buf</td>\n",
    "        <td>string——路径</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>sep</td>\n",
    "        <td>string——分隔符，read_csv默认为“,”</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>na_rep</td>\n",
    "        <td>string——缺失值</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>columns</td>\n",
    "        <td>list——写出的列名</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>header</td>\n",
    "        <td>boolean——是否将列名写出</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>index</td>\n",
    "        <td>boolean——是否将行名（索引）写出</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>index_label</td>\n",
    "        <td>sequence——索引名</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>mode</td>\n",
    "        <td>特定string——写入模式</td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>encoding</td>\n",
    "        <td>特定string——存储文件编码格式</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单信息表写入文本文件前目录内文件列表为：\n",
      " ['data']\n",
      "订单信息表写入文本文件后目录内文件列表为：\n",
      " ['data', 'orderInfo.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('订单信息表写入文本文件前目录内文件列表为：\\n', os.listdir('./pandas'))\n",
    "order.to_csv('./pandas/orderInfo.csv', sep=';', index=False)\n",
    "print('订单信息表写入文本文件后目录内文件列表为：\\n', os.listdir('./pandas'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 读写excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pd.read_excel(io, sheetname=0, header=0, index_col=None, names=None, dtype=None)\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>参数</td>\n",
    "        <td>说明</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>io</td>\n",
    "        <td>string——路径</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>sheetname</td>\n",
    "        <td>string, int——excel表内数据的分表位置</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>names</td>\n",
    "        <td>array——列名</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>header</td>\n",
    "        <td>int或sequence——将某行数据作为列名，int表示将该列作为列名，sequence表示多重索引</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>index_col</td>\n",
    "        <td>int、sequence、False——索引列位置，sequence为多重索引</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>dtype</td>\n",
    "        <td>dict——写入的数据类型，（列名，数据格式）</td>\n",
    "    </tr>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "客户信息表长度为： 734\n"
     ]
    }
   ],
   "source": [
    "user = pd.read_excel('./pandas/data/users.xlsx')## 读取user.xlsx文件\n",
    "print('客户信息表长度为：',len(user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- excel 存储"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " ``` \n",
    "pd.DataFrame.to_excel(self, excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None,\n",
    "                 header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None,\n",
    "                 merge_cells=True, encoding=None, inf_rep='inf', verbose=True, freeze_panes=None)```\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "客户信息表写入excel文件前目录内文件列表为：\n",
      " ['data', 'orderInfo.csv']\n",
      "客户信息表写入excel文件后目录内文件列表为：\n",
      " ['data', 'orderInfo.csv', 'userInfo.xlsx']\n"
     ]
    }
   ],
   "source": [
    "print('客户信息表写入excel文件前目录内文件列表为：\\n', os.listdir('./pandas'))\n",
    "user.to_excel('./pandas/userInfo.xlsx')\n",
    "print('客户信息表写入excel文件后目录内文件列表为：\\n', os.listdir('./pandas'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 小任务\n",
    "    - 根据餐饮企业给出的数据（以数据库形式存在，IP 127.0.0.1，用户名root，密码123000，数据库名testdb，表名meal_order_detail），读取订单详情数据库的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\Python_36\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1366, \"Incorrect string value: '\\\\xD6\\\\xD0\\\\xB9\\\\xFA\\\\xB1\\\\xEA...' for column 'VARIABLE_VALUE' at row 518\")\n",
      "  result = self._query(query)\n",
      "D:\\Program Files\\Anaconda3\\envs\\Python_36\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (3719, \"'utf8' is currently an alias for the character set UTF8MB3, which will be replaced by UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.\")\n",
      "  result = self._query(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表1的长度为： 2779\n",
      "订单详情表2的长度为： 3647\n",
      "订单详情表3的长度为： 3611\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "## 创建一个mysql连接器，用户名为root，密码为1234\n",
    "## 地址为127.0.0.1，数据库名称为testdb\n",
    "engine = create_engine('mysql+pymysql://root:123000@127.0.0.1:3306/testdb?charset=utf8')\n",
    "## 使用read_sql_table读取订单详情表格\n",
    "order1 = pd.read_sql_table('meal_order_detail1',con=engine)\n",
    "print(\"订单详情表1的长度为：\",len(order1))\n",
    "order2 = pd.read_sql_table('meal_order_detail2',con=engine)\n",
    "print(\"订单详情表2的长度为：\",len(order2))\n",
    "order3 = pd.read_sql_table('meal_order_detail3',con=engine)\n",
    "print(\"订单详情表3的长度为：\",len(order3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 读取订单信息 csv数据\n",
    "- 分隔符','，编码'UTF-8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单信息表的长度为： 945\n"
     ]
    }
   ],
   "source": [
    "## 使用read_table读取订单信息表\n",
    "orderInfo = pd.read_table('./pandas/data/meal_order_info.csv', sep = ',',encoding = 'gbk')\n",
    "print('订单信息表的长度为：',len(orderInfo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 读取客户信息Excel数据\n",
    "- 表名 Sheet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "客户信息表的长度为： 734\n"
     ]
    }
   ],
   "source": [
    "## 读取user.xlsx文件\n",
    "userInfo = pd.read_excel('./pandas/data/users.xlsx', sheetname = 'users1')\n",
    "print('客户信息表的长度为：',len(userInfo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame的常用操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 查看数据的 大小 维度 等基本信息\n",
    "- 查看销售菜品数据的基本统计信息\n",
    "- 剔除 全为空值 或者 所有元素取值相同的列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame的常用属性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- values index columns dtypes ===  元素  索引 列名  类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\Python_36\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1366, \"Incorrect string value: '\\\\xD6\\\\xD0\\\\xB9\\\\xFA\\\\xB1\\\\xEA...' for column 'VARIABLE_VALUE' at row 518\")\n",
      "  result = self._query(query)\n",
      "D:\\Program Files\\Anaconda3\\envs\\Python_36\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (3719, \"'utf8' is currently an alias for the character set UTF8MB3, which will be replaced by UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.\")\n",
      "  result = self._query(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表的索引为： RangeIndex(start=0, stop=2779, step=1)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "## 创建数据库连接\n",
    "engine = create_engine('mysql+pymysql://root:123000@127.0.0.1:3306/testdb?charset=utf8')\n",
    "detail= pd.read_sql_table('meal_order_detail1',con = engine)\n",
    "print('订单详情表的索引为：', detail.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表的所有值为： \n",
      " [['2956' '417' '610062' ..., 'NA' 'caipu/104001.jpg' '1442']\n",
      " ['2958' '417' '609957' ..., 'NA' 'caipu/202003.jpg' '1442']\n",
      " ['2961' '417' '609950' ..., 'NA' 'caipu/303001.jpg' '1442']\n",
      " ..., \n",
      " ['6756' '774' '609949' ..., 'NA' 'caipu/404005.jpg' '1138']\n",
      " ['6763' '774' '610014' ..., 'NA' 'caipu/302003.jpg' '1138']\n",
      " ['6764' '774' '610017' ..., 'NA' 'caipu/302006.jpg' '1138']]\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表的所有值为：','\\n', detail.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表的列名为： \n",
      " Index(['detail_id', 'order_id', 'dishes_id', 'logicprn_name',\n",
      "       'parent_class_name', 'dishes_name', 'itemis_add', 'counts', 'amounts',\n",
      "       'cost', 'place_order_time', 'discount_amt', 'discount_reason',\n",
      "       'kick_back', 'add_inprice', 'add_info', 'bar_code', 'picture_file',\n",
      "       'emp_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表的列名为：','\\n', detail.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表的数据类型为： \n",
      " detail_id                    object\n",
      "order_id                     object\n",
      "dishes_id                    object\n",
      "logicprn_name                object\n",
      "parent_class_name            object\n",
      "dishes_name                  object\n",
      "itemis_add                   object\n",
      "counts                      float64\n",
      "amounts                     float64\n",
      "cost                         object\n",
      "place_order_time     datetime64[ns]\n",
      "discount_amt                 object\n",
      "discount_reason              object\n",
      "kick_back                    object\n",
      "add_inprice                  object\n",
      "add_info                     object\n",
      "bar_code                     object\n",
      "picture_file                 object\n",
      "emp_id                       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表的数据类型为：','\\n', detail.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- size ndim shape <==> 元素个数  维度数  数据形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表的元素个数为： 52801\n",
      "订单详情表的维度数为： 2\n",
      "订单详情表的形状为： (2779, 19)\n"
     ]
    }
   ],
   "source": [
    "## 查看DataFrame的元素个数\n",
    "print('订单详情表的元素个数为：', detail.size)\n",
    "print('订单详情表的维度数为：', detail.ndim) ## 查看DataFrame的维度数\n",
    "print('订单详情表的形状为：', detail.shape) ## 查看DataFrame的形状"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- T  ==>  转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表转置前形状为： (2779, 19)\n",
      "订单详情表转置后形状为为： (19, 2779)\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表转置前形状为：',detail.shape)\n",
    "print('订单详情表转置后形状为为：',detail.T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 增删改查"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 增加/删除一行/一列\n",
    "- 修改某一值\n",
    "- 在某个区间进行值替换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DataFrame的单列数据是一个Series\n",
    "- DataFrame是一个带标签的二维数组，标签相当于列名\n",
    "- 以字典访问某一个key的值的方式使用对应的列名，即可实现数据访问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表中的order_id的形状为: \n",
      " (2779,)\n"
     ]
    }
   ],
   "source": [
    "## 使用访问字典方式取出orderInfo中的某一列\n",
    "order_id = detail['order_id']\n",
    "print('订单详情表中的order_id的形状为:','\\n',order_id.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 也可以以访问属性的方式访问数据，不建议使用，与方法重名就不好了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表中的order_id的形状为: \n",
      " (2779,)\n"
     ]
    }
   ],
   "source": [
    "order_id = detail.order_id\n",
    "print('订单详情表中的order_id的形状为:','\\n',order_id.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 单列多行数据获取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表中的dishes_name前5个元素为： \n",
      " 0     蒜蓉生蚝\n",
      "1    蒙古烤羊腿\n",
      "2     大蒜苋菜\n",
      "3    芝麻烤紫菜\n",
      "4      蒜香包\n",
      "Name: dishes_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "dishes_name5 = detail['dishes_name'][:5]\n",
    "print('订单详情表中的dishes_name前5个元素为：','\\n',dishes_name5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 多列数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表中的order_id和dishes_name前5个元素为： \n",
      "   order_id dishes_name\n",
      "0      417        蒜蓉生蚝\n",
      "1      417       蒙古烤羊腿\n",
      "2      417        大蒜苋菜\n",
      "3      417       芝麻烤紫菜\n",
      "4      417         蒜香包\n"
     ]
    }
   ],
   "source": [
    "orderDish = detail[['order_id','dishes_name']][:5]\n",
    "print('订单详情表中的order_id和dishes_name前5个元素为：', '\\n',orderDish)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 部分行数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表的1-6行元素为： \n",
      "   detail_id order_id dishes_id logicprn_name parent_class_name dishes_name  \\\n",
      "1      2958      417    609957            NA                NA       蒙古烤羊腿   \n",
      "2      2961      417    609950            NA                NA        大蒜苋菜   \n",
      "3      2966      417    610038            NA                NA       芝麻烤紫菜   \n",
      "4      2968      417    610003            NA                NA         蒜香包   \n",
      "5      1899      301    610019            NA                NA         白斩鸡   \n",
      "\n",
      "  itemis_add  counts  amounts cost    place_order_time discount_amt  \\\n",
      "1          0     1.0     48.0   NA 2016-08-01 11:07:00           NA   \n",
      "2          0     1.0     30.0   NA 2016-08-01 11:07:00           NA   \n",
      "3          0     1.0     25.0   NA 2016-08-01 11:11:00           NA   \n",
      "4          0     1.0     13.0   NA 2016-08-01 11:11:00           NA   \n",
      "5          0     1.0     88.0   NA 2016-08-01 11:15:00           NA   \n",
      "\n",
      "  discount_reason kick_back add_inprice add_info bar_code      picture_file  \\\n",
      "1              NA        NA           0       NA       NA  caipu/202003.jpg   \n",
      "2              NA        NA           0       NA       NA  caipu/303001.jpg   \n",
      "3              NA        NA           0       NA       NA  caipu/105002.jpg   \n",
      "4              NA        NA           0       NA       NA  caipu/503002.jpg   \n",
      "5              NA        NA           0       NA       NA  caipu/204002.jpg   \n",
      "\n",
      "  emp_id  \n",
      "1   1442  \n",
      "2   1442  \n",
      "3   1442  \n",
      "4   1442  \n",
      "5   1095  \n"
     ]
    }
   ],
   "source": [
    "order5 = detail[:][1:6]\n",
    "print('订单详情表的1-6行元素为：','\\n',order5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- head  tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表中前五行数据为 \n",
      "   detail_id order_id dishes_id dishes_name  amounts    place_order_time\n",
      "0      2956      417    610062        蒜蓉生蚝     49.0 2016-08-01 11:05:00\n",
      "1      2958      417    609957       蒙古烤羊腿     48.0 2016-08-01 11:07:00\n",
      "2      2961      417    609950        大蒜苋菜     30.0 2016-08-01 11:07:00\n",
      "3      2966      417    610038       芝麻烤紫菜     25.0 2016-08-01 11:11:00\n",
      "4      2968      417    610003         蒜香包     13.0 2016-08-01 11:11:00\n",
      "订单详情表中后五个元素为： \n",
      "      detail_id order_id dishes_id dishes_name  amounts    place_order_time\n",
      "2774      6750      774    610011       白饭/大碗     10.0 2016-08-10 21:56:00\n",
      "2775      6742      774    609996         牛尾汤     40.0 2016-08-10 21:56:00\n",
      "2776      6756      774    609949      意文柠檬汁      13.0 2016-08-10 22:01:00\n",
      "2777      6763      774    610014        金玉良缘     30.0 2016-08-10 22:03:00\n",
      "2778      6764      774    610017        酸辣藕丁     33.0 2016-08-10 22:04:00\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表中前五行数据为','\\n',detail.head()[['detail_id', 'order_id', 'dishes_id', 'dishes_name', 'amounts', 'place_order_time']])\n",
    "print('订单详情表中后五个元素为：','\\n',detail.tail()[['detail_id', 'order_id', 'dishes_id', 'dishes_name', 'amounts', 'place_order_time']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- loc iloc\n",
    "- loc  ==> 索引名称的切片方法 ==》 实现所有单层索引操作\n",
    "- pd.DataFrame.loc[行索引名称 或 条件, 列索引名称]\n",
    "- iloc  ==》 接收的必须是 行索引 和 列索引 的位置\n",
    "- pd.DataFrame.iloc[行索引位置, 列索引位置]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用loc提取dishes_name列的size为： 2779\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     蒜蓉生蚝\n",
       "1    蒙古烤羊腿\n",
       "2     大蒜苋菜\n",
       "3    芝麻烤紫菜\n",
       "4      蒜香包\n",
       "Name: dishes_name, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dishes_name1 = detail.loc[:, 'dishes_name']\n",
    "print('使用loc提取dishes_name列的size为：', dishes_name1.size)\n",
    "print()\n",
    "dishes_name1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用iloc提取第5列的size为： 2779\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     蒜蓉生蚝\n",
       "1    蒙古烤羊腿\n",
       "2     大蒜苋菜\n",
       "3    芝麻烤紫菜\n",
       "4      蒜香包\n",
       "Name: dishes_name, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dishes_name2 = detail.iloc[:,5]\n",
    "print('使用iloc提取第5列的size为：', dishes_name2.size)\n",
    "print()\n",
    "dishes_name2[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 多列切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用loc提取order_id和dishes_name列的size为： 5558\n"
     ]
    }
   ],
   "source": [
    "orderDish1 = detail.loc[:,['order_id','dishes_name']]\n",
    "print('使用loc提取order_id和dishes_name列的size为：', orderDish1.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用iloc提取第1和第3列的size为： 5558\n"
     ]
    }
   ],
   "source": [
    "orderDish2 = detail.iloc[:,[1,3]]\n",
    "print('使用iloc提取第1和第3列的size为：', orderDish1.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 花式切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "列名为order_id和dishes_name的行名为3的数据为：\n",
      " order_id         417\n",
      "dishes_name    芝麻烤紫菜\n",
      "Name: 3, dtype: object\n",
      "----------------------------\n",
      "列名为order_id和dishes_name行名为2,3,4,5,6的数据为：\n",
      "   order_id dishes_name\n",
      "2      417        大蒜苋菜\n",
      "3      417       芝麻烤紫菜\n",
      "4      417         蒜香包\n",
      "5      301         白斩鸡\n",
      "6      301        香烤牛排\n",
      "----------------------------\n",
      "列位置为1和3行位置为3的数据为：\n",
      " order_id         417\n",
      "logicprn_name     NA\n",
      "Name: 3, dtype: object\n",
      "----------------------------\n",
      "列位置为1和3行位置为2,3,4,5,6的数据为：\n",
      "   order_id logicprn_name\n",
      "2      417            NA\n",
      "3      417            NA\n",
      "4      417            NA\n",
      "5      301            NA\n",
      "6      301            NA\n"
     ]
    }
   ],
   "source": [
    "print('列名为order_id和dishes_name的行名为3的数据为：\\n', detail.loc[3,['order_id','dishes_name']])\n",
    "print('----------------------------')\n",
    "print('列名为order_id和dishes_name行名为2,3,4,5,6的数据为：\\n', detail.loc[2:6,['order_id','dishes_name']])\n",
    "print('----------------------------')\n",
    "print('列位置为1和3行位置为3的数据为：\\n',detail.iloc[3,[1,3]])\n",
    "print('----------------------------')\n",
    "print('列位置为1和3行位置为2,3,4,5,6的数据为：\\n', detail.iloc[2:7,[1,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 可以看出  loc  若行索引名称是一个区间，则前后均是闭区间\n",
    "-        iloc 行索引位置或列索引位置是一个区间，则前闭后开区间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 条件切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detail中order_id为458的dishes_name为：\n",
      "     order_id dishes_name\n",
      "145      458       蒜香辣花甲\n",
      "146      458        剁椒鱼头\n",
      "147      458     凉拌蒜蓉西兰花\n",
      "148      458        木须豌豆\n",
      "149      458        辣炒鱿鱼\n",
      "150      458        酸辣藕丁\n",
      "151      458       炝炒大白菜\n",
      "152      458       香菇鸡肉粥\n",
      "153      458        干锅田鸡\n",
      "154      458     桂圆枸杞鸽子汤\n",
      "155      458       五香酱驴肉\n",
      "156      458    路易拉菲红酒干红\n",
      "157      458       避风塘炒蟹\n",
      "158      458       白饭/大碗\n"
     ]
    }
   ],
   "source": [
    "## loc内部传入表达式\n",
    "print('detail中order_id为458的dishes_name为：\\n', detail.loc[detail['order_id']=='458', ['order_id','dishes_name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detail中order_id为458的第1,5列数据为：\n",
      "     order_id dishes_name\n",
      "145      458       蒜香辣花甲\n",
      "146      458        剁椒鱼头\n",
      "147      458     凉拌蒜蓉西兰花\n",
      "148      458        木须豌豆\n",
      "149      458        辣炒鱿鱼\n",
      "150      458        酸辣藕丁\n",
      "151      458       炝炒大白菜\n",
      "152      458       香菇鸡肉粥\n",
      "153      458        干锅田鸡\n",
      "154      458     桂圆枸杞鸽子汤\n",
      "155      458       五香酱驴肉\n",
      "156      458    路易拉菲红酒干红\n",
      "157      458       避风塘炒蟹\n",
      "158      458       白饭/大碗\n"
     ]
    }
   ],
   "source": [
    "print('detail中order_id为458的第1,5列数据为：\\n', detail.iloc[(detail['order_id']=='458').values,[1,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(detail['order_id']=='458').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ix\n",
    "- loc 和 iloc的融合，既可以接收索引名称，又可以接收位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "列名为dishes_name，行名为2,3,4,5,6的数据：\n",
      " 2     大蒜苋菜\n",
      "3    芝麻烤紫菜\n",
      "4      蒜香包\n",
      "5      白斩鸡\n",
      "6     香烤牛排\n",
      "Name: dishes_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('列名为dishes_name，行名为2,3,4,5,6的数据：\\n', detail.loc[2:6, 'dishes_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "列位置为5,行位置为2至6的数据为：\n",
      " 2     大蒜苋菜\n",
      "3    芝麻烤紫菜\n",
      "4      蒜香包\n",
      "5      白斩鸡\n",
      "Name: dishes_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('列位置为5,行位置为2至6的数据为：\\n',detail.iloc[2:6,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "列位置为5行名为2至6的数据为： \n",
      " 2     大蒜苋菜\n",
      "3    芝麻烤紫菜\n",
      "4      蒜香包\n",
      "5      白斩鸡\n",
      "6     香烤牛排\n",
      "Name: dishes_name, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\Python_36\\lib\\site-packages\\ipykernel\\__main__.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "print('列位置为5行名为2至6的数据为：', '\\n',detail.ix[2:6,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用ix参数时，尽量保持行索引名称和行索引位置重叠，使用时就无需考虑取值区间的问题，一律为闭区间\n",
    "- 数据量巨大时，效率低于loc 和 iloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **更改DataFrame数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "更改后detail中order_id为458的order_id为：\n",
      " Series([], Name: order_id, dtype: object)\n",
      "更改后detail中order_id为45800的order_id为：\n",
      " 145    45800\n",
      "146    45800\n",
      "147    45800\n",
      "148    45800\n",
      "149    45800\n",
      "150    45800\n",
      "151    45800\n",
      "152    45800\n",
      "153    45800\n",
      "154    45800\n",
      "155    45800\n",
      "156    45800\n",
      "157    45800\n",
      "158    45800\n",
      "Name: order_id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "detail.loc[detail['order_id']=='458', 'order_id'] = '45800'\n",
    "print('更改后detail中order_id为458的order_id为：\\n', detail.loc[detail['order_id']=='458','order_id'])\n",
    "print('更改后detail中order_id为45800的order_id为：\\n', detail.loc[detail['order_id']=='45800','order_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 直接对DataFrame更改，操作无法撤销，注意备份"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **DataFrame增添数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detail新增列payment的前五行为： \n",
      " 0    49.0\n",
      "1    48.0\n",
      "2    30.0\n",
      "3    25.0\n",
      "4    13.0\n",
      "Name: payment, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "detail['payment'] =  detail['counts']*detail['amounts']\n",
    "print('detail新增列payment的前五行为：','\\n', detail['payment'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 若新增一列值是相同的，直接赋常量即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detail新增列pay_way的前五行为： \n",
      " 0    现金支付\n",
      "1    现金支付\n",
      "2    现金支付\n",
      "3    现金支付\n",
      "4    现金支付\n",
      "Name: pay_way, dtype: object\n"
     ]
    }
   ],
   "source": [
    "detail['pay_way'] = '现金支付'\n",
    "print('detail新增列pay_way的前五行为：','\\n', detail['pay_way'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **删除某列或某行**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `pd.DataFrame.drop(self, labels, axis=0, level=None, inplace=False, errors='raise')`\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>参数</td>\n",
    "        <td>说明</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>labels</td>\n",
    "        <td>string或array——删除的行或列的标签</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>axis</td>\n",
    "        <td>0或 1——操作轴向，默认0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>levels</td>\n",
    "        <td>int或索引名——标签所在级别</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>inplace</td>\n",
    "        <td>boolean——是否对原数据生效</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 删除某列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "删除pay_way前deatil的列索引为： \n",
      " Index(['detail_id', 'order_id', 'dishes_id', 'logicprn_name',\n",
      "       'parent_class_name', 'dishes_name', 'itemis_add', 'counts', 'amounts',\n",
      "       'cost', 'place_order_time', 'discount_amt', 'discount_reason',\n",
      "       'kick_back', 'add_inprice', 'add_info', 'bar_code', 'picture_file',\n",
      "       'emp_id', 'payment', 'pay_way'],\n",
      "      dtype='object')\n",
      "删除pay_way后detail的列索引为： \n",
      " Index(['detail_id', 'order_id', 'dishes_id', 'logicprn_name',\n",
      "       'parent_class_name', 'dishes_name', 'itemis_add', 'counts', 'amounts',\n",
      "       'cost', 'place_order_time', 'discount_amt', 'discount_reason',\n",
      "       'kick_back', 'add_inprice', 'add_info', 'bar_code', 'picture_file',\n",
      "       'emp_id', 'payment'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('删除pay_way前deatil的列索引为：','\\n',detail.columns)\n",
    "detail.drop(labels = 'pay_way',axis = 1,inplace = True)\n",
    "print('删除pay_way后detail的列索引为：','\\n',detail.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 删除某行\n",
    "- labels参数换位对应的行索引，axis设为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "删除1-10行前detail的长度为： 2779\n",
      "删除1-10行后detail的列索引为： 2769\n"
     ]
    }
   ],
   "source": [
    "print('删除1-10行前detail的长度为：',len(detail))\n",
    "detail.drop(labels = range(1,11),axis = 0,inplace = True)\n",
    "print('删除1-10行后detail的列索引为：',len(detail))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **描述分析DataFrame数据**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数值型数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>函数</td>\n",
    "        <td>说明</td>\n",
    "        <td>函数</td>\n",
    "        <td>说明</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>np.min</td>\n",
    "        <td>最小值</td>\n",
    "        <td>np.max</td>\n",
    "        <td>最大值</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>np.mean</td>\n",
    "        <td>均值</td>\n",
    "        <td>np.ptp</td>\n",
    "        <td>极差</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>np.median</td>\n",
    "        <td>中位数</td>\n",
    "        <td>np.std</td>\n",
    "        <td>标准差</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>np.std</td>\n",
    "        <td>方差</td>\n",
    "        <td>np.cov</td>\n",
    "        <td>协方差</td>\n",
    "    </tr>\n",
    "</table>\n",
    "- pandas库基于numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表中amount（价格）的平均值为： 45.3430841459\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print('订单详情表中amount（价格）的平均值为：', np.mean(detail['amounts']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表中amount（价格）的平均值为： 45.3430841459\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表中amount（价格）的平均值为：', detail['amounts'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- describe方法，一次性得到 数值特征的 非空值数目，均值，四分位数，标准差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表counts和amounts两列的描述性统计为：\n",
      "             counts      amounts\n",
      "count  2769.000000  2769.000000\n",
      "mean      1.111593    45.343084\n",
      "std       0.626521    36.841316\n",
      "min       1.000000     1.000000\n",
      "25%       1.000000    25.000000\n",
      "50%       1.000000    35.000000\n",
      "75%       1.000000    56.000000\n",
      "max      10.000000   178.000000\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表counts和amounts两列的描述性统计为：\\n', detail[['counts','amounts']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 类别型特征的描述性统计\n",
    "- 频数统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表dishes_name频数统计结果前10为：\n",
      " 白饭/大碗        91\n",
      "凉拌菠菜         77\n",
      "谷稻小庄         72\n",
      "麻辣小龙虾        65\n",
      "白饭/小碗        60\n",
      "五色糯米饭(七色)    58\n",
      "焖猪手          55\n",
      "芝士烩波士顿龙虾     55\n",
      "辣炒鱿鱼         53\n",
      "水煮鱼          47\n",
      "Name: dishes_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表dishes_name频数统计结果前10为：\\n', detail['dishes_name'].value_counts()[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pandas提供category类，可使用astype方法将目标特征的数据类型转换为category类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单信息表dishes_name列转变数据类型后为： category\n"
     ]
    }
   ],
   "source": [
    "detail['dishes_name'] = detail['dishes_name'].astype('category')\n",
    "print('订单信息表dishes_name列转变数据类型后为：',detail['dishes_name'].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pandas支持对category类型数据进行描述性统计，非空元素的数目，类别的数目，数目最多的类别，数目最多类别的数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单信息表dishes_name的描述统计结果为：\n",
      " count      2769\n",
      "unique      145\n",
      "top       白饭/大碗\n",
      "freq         91\n",
      "Name: dishes_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('订单信息表dishes_name的描述统计结果为：\\n', detail['dishes_name'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **小任务**\n",
    "    - 查看餐饮数据的大小与维度\n",
    "    - 统计餐饮菜品的销售情况\n",
    "    - 剔除全为空值或所有元素取值相同的列\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\Python_36\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1366, \"Incorrect string value: '\\\\xD6\\\\xD0\\\\xB9\\\\xFA\\\\xB1\\\\xEA...' for column 'VARIABLE_VALUE' at row 518\")\n",
      "  result = self._query(query)\n",
      "D:\\Program Files\\Anaconda3\\envs\\Python_36\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (3719, \"'utf8' is currently an alias for the character set UTF8MB3, which will be replaced by UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.\")\n",
      "  result = self._query(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表的维度为： 2\n",
      "订单信息表的维度为： 2\n",
      "客户信息表的维度为： 2\n",
      "订单详情表的形状为： (2779, 19)\n",
      "订单信息表的形状为： (945, 21)\n",
      "客户信息表的形状为： (734, 37)\n",
      "订单详情表的元素个数为： 52801\n",
      "订单信息表的元素个数为： 19845\n",
      "客户信息表的元素个数为： 27158\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "engine = create_engine('mysql+pymysql://root:123000@127.0.0.1:3306/testdb?charset=utf8')\n",
    "detail = pd.read_sql_table('meal_order_detail1', con = engine)\n",
    "order = pd.read_table('./pandas/data/meal_order_info.csv', sep = ',',encoding = 'gbk')\n",
    "user = pd.read_excel('./pandas/data/users.xlsx')\n",
    "print('订单详情表的维度为：', detail.ndim)\n",
    "print('订单信息表的维度为：', order.ndim)\n",
    "print('客户信息表的维度为：', user.ndim)\n",
    "\n",
    "print('订单详情表的形状为：', detail.shape)\n",
    "print('订单信息表的形状为：', order.shape)\n",
    "print('客户信息表的形状为：', user.shape)\n",
    "\n",
    "print('订单详情表的元素个数为：', detail.size)\n",
    "print('订单信息表的元素个数为：', order.size)\n",
    "print('客户信息表的元素个数为：', user.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "---------------餐饮菜品的销售情况---------------\n",
      "------------------------------------------------\n",
      "订单详情表counts和amounts两列的描述性统计为：\n",
      "             counts      amounts\n",
      "count  2779.000000  2779.000000\n",
      "mean      1.111191    45.337172\n",
      "std       0.625428    36.808550\n",
      "min       1.000000     1.000000\n",
      "25%       1.000000    25.000000\n",
      "50%       1.000000    35.000000\n",
      "75%       1.000000    56.000000\n",
      "max      10.000000   178.000000\n",
      "订单信息表order_id(订单编号)与dishes_name(菜品名称)的描述性统计结果为： \n",
      "        order_id dishes_name\n",
      "count      2779        2779\n",
      "unique      278         145\n",
      "top         392       白饭/大碗\n",
      "freq         24          92\n"
     ]
    }
   ],
   "source": [
    "print('------------------------------------------------')\n",
    "print('---------------餐饮菜品的销售情况---------------')\n",
    "print('------------------------------------------------')\n",
    "print('订单详情表counts和amounts两列的描述性统计为：\\n', detail.loc[:, ['counts','amounts']].describe())\n",
    "\n",
    "detail['order_id'] = detail['order_id'].astype('category')\n",
    "detail['dishes_name'] = detail['dishes_name'].astype('category')\n",
    "print('''订单信息表order_id(订单编号)与dishes_name(菜品名称)的描述性统计结果为：''', '\\n', detail[['order_id','dishes_name']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "-----------------剔除全为空值或所有元素取值相同的列-----------------\n",
      "----------即describe().loc['count'] == 0的列和标准差为0的列---------\n",
      "--------------------------------------------------------------------\n",
      "去除的列的数目为： 0\n",
      "去除后数据的形状为： (2779, 19)\n",
      "去除的列的数目为： 7\n",
      "去除后数据的形状为： (945, 14)\n",
      "去除的列的数目为： 13\n",
      "去除后数据的形状为： (734, 24)\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------------------------------------')\n",
    "print('-----------------剔除全为空值或所有元素取值相同的列-----------------')\n",
    "print('''----------即describe().loc['count'] == 0的列和标准差为0的列---------''')\n",
    "print('--------------------------------------------------------------------')\n",
    "## 定义一个函数去除全为空值的列和标准差为0的列\n",
    "def dropNullStd(data):\n",
    "    beforelen = data.shape[1]\n",
    "    colisNull = data.describe().loc['count'] == 0\n",
    "    for i in range(len(colisNull)):\n",
    "        if colisNull[i]:\n",
    "            data.drop(colisNull.index[i],axis = 1,inplace =True)\n",
    "\n",
    "    stdisZero = data.describe().loc['std'] == 0\n",
    "    for i in range(len(stdisZero)):\n",
    "        if stdisZero[i]:\n",
    "            data.drop(stdisZero.index[i],axis = 1,inplace =True)\n",
    "    afterlen = data.shape[1]\n",
    "    print('去除的列的数目为：',beforelen-afterlen)\n",
    "    print('去除后数据的形状为：',data.shape)\n",
    "dropNullStd(detail)\n",
    "\n",
    "##使用dropNullStd函数对订单信息表操作\n",
    "dropNullStd(order)\n",
    "\n",
    "##使用dropNullStd函数对客户信息表操作\n",
    "dropNullStd(user)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 转换与处理时间序列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将订单信息表数据中的时间转换为标准的时间格式\n",
    "- 提取订单信息表数据中的年月日和星期信息\n",
    "- 查看餐饮的数据时间分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **转换字符串时间为标准时间**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>函数</td>\n",
    "        <td>说明</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Timestamp</td>\n",
    "        <td>表示某个时间点，大部分场景数据都是该形式</td>\n",
    "     </tr>\n",
    "    <tr>\n",
    "        <td>Period</td>\n",
    "        <td>时间跨度，或某个时间段</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Timedelta</td>\n",
    "        <td>不同单位的时间，如1d 1.5h  3min  4s</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>DatetimeIndex</td>\n",
    "        <td>TimeStamp构成的index，用来作为Series或DataFrame的索引</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>PeriodIndex</td>\n",
    "        <td>Period构成的index，用来作为Series或DataFrame的索引</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>TimedeltaIndex</td>\n",
    "        <td>Timedelta构成的index，用来作为Series或DataFrame的索引</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 多数情况将字符串转换为Timestamp\n",
    "- to_datetime函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进行转换前订单信息表lock_time的类型为： object\n",
      "进行转换后订单信息表lock_time的类型为： datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "order = pd.read_table('./pandas/data/meal_order_info.csv', sep = ',',encoding = 'gbk')\n",
    "print('进行转换前订单信息表lock_time的类型为：', order['lock_time'].dtypes)\n",
    "order['lock_time'] = pd.to_datetime(order['lock_time'])\n",
    "print('进行转换后订单信息表lock_time的类型为：', order['lock_time'].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 表示时间范围限制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最小时间为： 1677-09-21 00:12:43.145225\n",
      "最大时间为： 2262-04-11 23:47:16.854775807\n"
     ]
    }
   ],
   "source": [
    "print('最小时间为：', pd.Timestamp.min)\n",
    "print('最大时间为：', pd.Timestamp.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将数据提取出来，转换为DatetimeIndex和PeriodIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转换为DatetimeIndex后数据的类型为：\n",
      " <class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n"
     ]
    }
   ],
   "source": [
    "dateIndex = pd.DatetimeIndex(order['lock_time'])\n",
    "print('转换为DatetimeIndex后数据的类型为：\\n',type(dateIndex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转换为DatetimeIndex后数据的类型为：\n",
      " <class 'pandas.core.indexes.period.PeriodIndex'>\n"
     ]
    }
   ],
   "source": [
    "periodIndex = pd.PeriodIndex(order['lock_time'],freq = 'S')\n",
    "print('转换为DatetimeIndex后数据的类型为：\\n',type(periodIndex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeriodIndex(['2016-08-01 11:11:46', '2016-08-01 11:31:55',\n",
       "             '2016-08-01 12:54:37', '2016-08-01 13:08:20',\n",
       "             '2016-08-01 13:07:16'],\n",
       "            dtype='period[S]', name='lock_time', freq='S')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "periodIndex[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用 PeriodIndex 时，要通过freq指定时间间隔，Y M D H M S "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **提取时间序列数据信息**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 提取 年份 月份等数据\n",
    "- Timestamp类属性\n",
    "\n",
    "|属性|说明|属性|说明|\n",
    "|-:-|-:-|-:-|-:-|\n",
    "|day|日|dayofweek|一周第几天|\n",
    "|dayofyear|一年第几天|hour|时|\n",
    "|is_leap_year|是否闰年|minute|分|\n",
    "|month|月|quarter|季节|\n",
    "|second|秒|week|周|\n",
    "|weekofyear|一年第几周|year|年|\n",
    "|date|日期|time|时间|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 提取时间序列数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lock_time中的年份数据前5个为： [2016, 2016, 2016, 2016, 2016]\n",
      "lock_time中的月份数据前5个为： [8, 8, 8, 8, 8]\n",
      "lock_time中的日期数据前5个为： [1, 1, 1, 1, 1]\n",
      "lock_time中的星期名称数据前5个为： ['Monday', 'Monday', 'Monday', 'Monday', 'Monday']\n"
     ]
    }
   ],
   "source": [
    "year1 = [i.year for i in order['lock_time']]\n",
    "print('lock_time中的年份数据前5个为：',year1[:5])\n",
    "month1 = [i.month for i in order['lock_time']]\n",
    "print('lock_time中的月份数据前5个为：',month1[:5])\n",
    "day1 = [i.day for i in order['lock_time']]\n",
    "print('lock_time中的日期数据前5个为：',day1[:5])\n",
    "weekday1 = [i.weekday_name for i in order['lock_time']]\n",
    "print('lock_time中的星期名称数据前5个为：',weekday1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dateIndex中的星期名称数据前5个为：\n",
      " Index(['Monday', 'Monday', 'Monday', 'Monday', 'Monday'], dtype='object', name='lock_time')\n",
      "periodIndex中的星期标号数据前5个为： Int64Index([0, 0, 0, 0, 0], dtype='int64', name='lock_time')\n"
     ]
    }
   ],
   "source": [
    "print('dateIndex中的星期名称数据前5个为：\\n', dateIndex.weekday_name[:5])\n",
    "print('periodIndex中的星期标号数据前5个为：', periodIndex.weekday[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **时间数据加减**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Timedelta类\n",
    "- Timedelta类函数中时间周期没有年和月\n",
    "    - weeks days hours minutes seconds milliseconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 加运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lock_time在加上一天前前5行数据为：\n",
      " 0   2016-08-01 11:11:46\n",
      "1   2016-08-01 11:31:55\n",
      "2   2016-08-01 12:54:37\n",
      "3   2016-08-01 13:08:20\n",
      "4   2016-08-01 13:07:16\n",
      "Name: lock_time, dtype: datetime64[ns]\n",
      "lock_time在加上一天前前5行数据为：\n",
      " 0   2016-08-02 11:11:46\n",
      "1   2016-08-02 11:31:55\n",
      "2   2016-08-02 12:54:37\n",
      "3   2016-08-02 13:08:20\n",
      "4   2016-08-02 13:07:16\n",
      "Name: lock_time, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "## 将lock_time数据向后平移一天\n",
    "time1 = order['lock_time']+pd.Timedelta(days = 1) \n",
    "print('lock_time在加上一天前前5行数据为：\\n',order['lock_time'][:5])\n",
    "print('lock_time在加上一天前前5行数据为：\\n',time1[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 减运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lock_time减去2017年1月1日0点0时0分后的数据：\n",
      " 0   -153 days +11:11:46\n",
      "1   -153 days +11:31:55\n",
      "2   -153 days +12:54:37\n",
      "3   -153 days +13:08:20\n",
      "4   -153 days +13:07:16\n",
      "Name: lock_time, dtype: timedelta64[ns]\n",
      "lock_time减去time1后的数据类型为： timedelta64[ns]\n"
     ]
    }
   ],
   "source": [
    "timeDelta = order['lock_time'] - pd.to_datetime('2017-1-1')\n",
    "print('lock_time减去2017年1月1日0点0时0分后的数据：\\n', timeDelta[:5])\n",
    "print('lock_time减去time1后的数据类型为：',timeDelta.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **小任务**\n",
    "    - 订单信息表中的两个时间特征由字符串格式转换为标准时间格式\n",
    "    - 提取菜品数据中的年月日和星期信息\n",
    "    - 查看订单信息表时间统计信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进行转换后订单信息表use_start_time和lock_time的类型为：\n",
      " use_start_time    datetime64[ns]\n",
      "lock_time         datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "order = pd.read_table('./pandas/data/meal_order_info.csv', sep = ',',encoding = 'gbk')\n",
    "order['use_start_time'] = pd.to_datetime(order['use_start_time'])\n",
    "order['lock_time'] = pd.to_datetime(order['lock_time'])\n",
    "print('进行转换后订单信息表use_start_time和lock_time的类型为：\\n', order[['use_start_time','lock_time']].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表中的前5条数据的年份信息为： [2016, 2016, 2016, 2016, 2016]\n",
      "订单详情表中的前5条数据的月份信息为： [8, 8, 8, 8, 8]\n",
      "订单详情表中的前5条数据的日期信息为： [1, 1, 1, 1, 1]\n",
      "订单详情表中的前5条数据的周信息为： [31, 31, 31, 31, 31]\n",
      "订单详情表中的前5条数据的星期信息为： [0, 0, 0, 0, 0]\n",
      "订单详情表中的前5条数据的星期名称信息为： ['Monday', 'Monday', 'Monday', 'Monday', 'Monday']\n"
     ]
    }
   ],
   "source": [
    "year = [i.year for i in order['lock_time']]## 提取年份信息\n",
    "month = [i.month for i in order['lock_time']]## 提取月份信息\n",
    "day = [i.day for i in  order['lock_time']]## 提取日期信息\n",
    "week = [i.week for i in  order['lock_time']]## 提取周信息\n",
    "weekday = [i.weekday() for i in  order['lock_time']]##提取星期信息\n",
    "## 提取星期名称信息\n",
    "weekname = [i.weekday_name for i in  order['lock_time']]\n",
    "print('订单详情表中的前5条数据的年份信息为：',year[:5])\n",
    "print('订单详情表中的前5条数据的月份信息为：',month[:5])\n",
    "print('订单详情表中的前5条数据的日期信息为：',day[:5])\n",
    "print('订单详情表中的前5条数据的周信息为：',week[:5])\n",
    "print('订单详情表中的前5条数据的星期信息为：',weekday[:5])\n",
    "print('订单详情表中的前5条数据的星期名称信息为：',weekname[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单最早的时间为： 2016-08-01 11:11:46\n",
      "订单最晚的时间为： 2016-08-31 21:56:12\n",
      "订单持续的时间为： 30 days 10:44:26\n",
      "平均点餐时间为： 0 days 01:12:10.326923\n",
      "最小点餐时间为： -1 days +00:05:03\n",
      "最大点餐时间为： 16 days 00:08:00\n"
     ]
    }
   ],
   "source": [
    "timemin = order['lock_time'].min()\n",
    "timemax = order['lock_time'].max()\n",
    "print('订单最早的时间为：',timemin)\n",
    "print('订单最晚的时间为：',timemax)\n",
    "print('订单持续的时间为：',timemax-timemin)\n",
    "\n",
    "chekTime = order['lock_time'] - order['use_start_time']\n",
    "print('平均点餐时间为：',chekTime.mean())\n",
    "print('最小点餐时间为：',chekTime.min())\n",
    "print('最大点餐时间为：',chekTime.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 通过求取最早时间和最晚时间的差值计算订单时间跨度\n",
    "- use_start_time 与 lock_time加减运算，可以看出开始点餐至结算订单的时间\n",
    "- 可以看出最短时间和最长时间均为异常值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分组与聚合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 按照时间对菜品订单数据进行拆分\n",
    "- 使用agg方法计算单日菜品销售的总额\n",
    "- 使用apply方法统计单日菜品销售数目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 分组聚合原理示意图\n",
    "![IMG_20180724_110755.jpg](https://i.loli.net/2018/07/24/5b569a5db489d.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- groupby\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>参数</td>\n",
    "        <td>说明</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>by</td>\n",
    "        <td>接收list、string、mapping或generator.用于确定进行分组的依据。如果传入的是一个函数，则对索引进行计算并分组；如果传入的是一个字典或者Series，则字典或者Series的值用来作为分组依据；如果传入一个Numpy数组，则数据的元素作为分组依据；如果传入的是字符串或者字符串列表，则使用这些字符串所代表的字段作为分组侬据。无默认\n",
    "</td>\n",
    "     </tr>\n",
    "    <tr>\n",
    "        <td>axis</td>\n",
    "        <td>接收int。表示操作的轴向，默认对列进行操作。默认为0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>level</td>\n",
    "        <td>接收int或者索引名。代表标签所在级别。默认为None</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>as_index</td>\n",
    "        <td>接收boolean，表示聚合后的聚合标签是否以DataFrame索引形式输出。默认为True</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>sort</td>\n",
    "        <td>接收boolean，表示是否对分组依据、分组标签进行排序。默认为True</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>groupkeys</td>\n",
    "        <td>接收boolea1E表示是否显示分组标签的名称。默认为True</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>squeeze</td>\n",
    "        <td>接收boolean，表不是否在允许的情况下对返回数据进行降维、默认为False</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 对菜品订单详情表依据订单编号进行分组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分组后的订单详情表为： <pandas.core.groupby.DataFrameGroupBy object at 0x0000000009D00390>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\Python_36\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1366, \"Incorrect string value: '\\\\xD6\\\\xD0\\\\xB9\\\\xFA\\\\xB1\\\\xEA...' for column 'VARIABLE_VALUE' at row 518\")\n",
      "  result = self._query(query)\n",
      "D:\\Program Files\\Anaconda3\\envs\\Python_36\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (3719, \"'utf8' is currently an alias for the character set UTF8MB3, which will be replaced by UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.\")\n",
      "  result = self._query(query)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('mysql+pymysql://root:123000@127.0.0.1:3306/testdb?charset=utf8')\n",
    "detail = pd.read_sql_table('meal_order_detail1',con = engine)\n",
    "detailGroup = detail[['order_id','counts','amounts']].groupby(by = 'order_id')\n",
    "print('分组后的订单详情表为：',detailGroup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 分组后结果不能直接查看，被存储在内存中，输出的是内存地址\n",
    "- 数据对象Groupby类似于Series与DataFrame\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>Groupby方法</td>\n",
    "        <td>说明</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>count</td>\n",
    "        <td>计算分组的数目，包括缺失值(NAN)</td>\n",
    "     </tr>\n",
    "    <tr>\n",
    "        <td>head</td>\n",
    "        <td>返回每组的前n个值</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>max</td>\n",
    "        <td>返回每组最大值</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>mean</td>\n",
    "        <td>返回每组的均值</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>median</td>\n",
    "        <td>返回每组的中位数</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>cumcount</td>\n",
    "        <td>对每个分组中的组员进行标记，0~n-1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>size</td>\n",
    "        <td>返回每组的大小，不包括NAN</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>min</td>\n",
    "        <td>返回每组最小值</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>std</td>\n",
    "        <td>返回每组的标准差</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>sum</td>\n",
    "        <td>返回每组的和</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 菜品订单表经过分组操作后的每一组的均值、标准差、中位数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表分组后前5组每组的均值为：\n",
      "           counts  amounts\n",
      "order_id                 \n",
      "1002      1.0000   32.000\n",
      "1003      1.2500   30.125\n",
      "1004      1.0625   43.875\n",
      "1008      1.0000   63.000\n",
      "1011      1.0000   57.700\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表分组后前5组每组的均值为：\\n', detailGroup.mean().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表分组后前5组每组的标准差为：\n",
      "            counts    amounts\n",
      "order_id                    \n",
      "1002      0.00000  16.000000\n",
      "1003      0.46291  21.383822\n",
      "1004      0.25000  31.195886\n",
      "1008      0.00000  64.880660\n",
      "1011      0.00000  50.077828\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表分组后前5组每组的标准差为：\\n', detailGroup.std().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表分组后前5组每组的大小为： \n",
      " order_id\n",
      "1002     7\n",
      "1003     8\n",
      "1004    16\n",
      "1008     5\n",
      "1011    10\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表分组后前5组每组的大小为：','\\n', detailGroup.size().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表分组后前5组每组的大小为： \n",
      "           counts  amounts\n",
      "order_id                 \n",
      "1002           7        7\n",
      "1003           8        8\n",
      "1004          16       16\n",
      "1008           5        5\n",
      "1011          10       10\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表分组后前5组每组的大小为：','\\n', detailGroup.count().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **使用 agg 方法聚合**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- agg 、aggregate都支持对每个分组应用某函数\n",
    "```\n",
    "    DataFrame.agg(func, axis=0, *agrs, **kwargs)\n",
    "    DataFrame.aggregate(func, axis=0, *agrs, **kwargs)\n",
    "```    \n",
    "<table>\n",
    "    <tr>\n",
    "        <td>参数</td>\n",
    "        <td>说明</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>func</td>\n",
    "        <td>list、dict、fuction——应用于每列或没行的函数</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>axis</td>\n",
    "        <td>0或1——操作轴向</td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用agg求当前数据对应的统计量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表的菜品销量与售价的和与均值为：\n",
      "            counts        amounts\n",
      "sum   3088.000000  125992.000000\n",
      "mean     1.111191      45.337172\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表的菜品销量与售价的和与均值为：\\n', detail[['counts','amounts']].agg([np.sum,np.mean]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 求取字段的不同统计量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表的菜品销量总和与售价的均值为：\n",
      " counts     3088.000000\n",
      "amounts      45.337172\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表的菜品销量总和与售价的均值为：\\n', detail.agg({'counts':np.sum,'amounts':np.mean}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 求取某些字段的多个统计量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "菜品订单详情表的菜品销量总和与售价的总和与均值为：\n",
      "       counts        amounts\n",
      "mean     NaN      45.337172\n",
      "sum   3088.0  125992.000000\n"
     ]
    }
   ],
   "source": [
    "print('菜品订单详情表的菜品销量总和与售价的总和与均值为：\\n', detail.agg({'counts':np.sum,'amounts':[np.mean,np.sum]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 自定义函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "菜品订单详情表的菜品销量两倍总和为： \n",
      " counts    6176.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "##自定义函数求两倍的和\n",
    "def DoubleSum(data):\n",
    "    s = data.sum()*2\n",
    "    return s\n",
    "print('菜品订单详情表的菜品销量两倍总和为：','\\n', detail.agg({'counts':DoubleSum},axis = 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在自定义函数中使用numpy库中的函数（np.sum,np.mean,nu.std...）时，\n",
    "    - 若计算单个列，则无法得到想要的结果；\n",
    "    - 多列数据同时计算不会出现这个问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表的菜品销量两倍总和为：\n",
      "    counts\n",
      "0     2.0\n",
      "1     2.0\n",
      "2     2.0\n",
      "3     2.0\n",
      "4     2.0\n"
     ]
    }
   ],
   "source": [
    "##自定义函数求两倍的和\n",
    "def DoubleSum1(data):\n",
    "    s = np.sum(data)*2\n",
    "    return s\n",
    "\n",
    "print('订单详情表的菜品销量两倍总和为：\\n', detail.agg({'counts':DoubleSum1},axis = 0).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2018-07-24_160041.png](https://i.loli.net/2018/07/24/5b56dcdbf010a.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表的菜品销量与售价的和的两倍为：\n",
      " counts       6176.0\n",
      "amounts    251984.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表的菜品销量与售价的和的两倍为：\\n', detail[['counts','amounts']].agg(DoubleSum1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 对每个字段的每一组使用相同的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表分组后前3组每组的均值为：\n",
      "           counts  amounts\n",
      "order_id                 \n",
      "1002      1.0000   32.000\n",
      "1003      1.2500   30.125\n",
      "1004      1.0625   43.875\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表分组后前3组每组的均值为：\\n', detailGroup.agg(np.mean).head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表分组后前3组每组的标准差为：\n",
      "            counts    amounts\n",
      "order_id                    \n",
      "1002      0.00000  16.000000\n",
      "1003      0.46291  21.383822\n",
      "1004      0.25000  31.195886\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表分组后前3组每组的标准差为：\\n', detailGroup.agg(np.std).head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 对不同字段应用不同函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情分组前3组每组菜品总数和售价均值为：\n",
      "           counts  amounts\n",
      "order_id                 \n",
      "1002         7.0   32.000\n",
      "1003        10.0   30.125\n",
      "1004        17.0   43.875\n"
     ]
    }
   ],
   "source": [
    "print('订单详情分组前3组每组菜品总数和售价均值为：\\n', detailGroup.agg({'counts':np.sum, 'amounts':np.mean}).head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **apply方法聚合**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 与agg类似，\n",
    "- 但与apply相比，agg方法传入的函数只能作用于整个DataFrame或Series\n",
    "- apply可以返回多列数据\n",
    "\n",
    "`pd.DataFrame.apply(self, func, axis=0, broadcast=False, raw=False, reduce=None, args=(), **kwds)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>参数</td>\n",
    "        <td>说明</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>func</td>\n",
    "        <td>fuction——应用于每列或每行的函数</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>axis</td>\n",
    "        <td>0或1——操作轴向</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>broadcast</td>\n",
    "        <td>boolean——是否进行广播</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>raw</td>\n",
    "        <td>boolean——是否直接将ndarray对象传递给函数</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>reduce</td>\n",
    "        <td>boolean或None——返回值的格式</td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 基本使用，与agg类似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表的菜品销量与售价的均值为：\n",
      " counts      1.111191\n",
      "amounts    45.337172\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表的菜品销量与售价的均值为：\\n', detail[['counts','amounts']].apply(np.mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- apply对Groupby对象进行聚合的方法和agg方法相同，只是，使用agg方法能实现对不同字段应用不同函数，而apply不行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表分组后前3组每组的均值为： \n",
      "           amounts  counts\n",
      "order_id                 \n",
      "1002       32.000  1.0000\n",
      "1003       30.125  1.2500\n",
      "1004       43.875  1.0625\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表分组后前3组每组的均值为：','\\n', detailGroup.apply(np.mean).head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表分组后前3组每组的标准差为： \n",
      "             amounts    counts\n",
      "order_id                     \n",
      "1002      14.813122  0.000000\n",
      "1003      20.002734  0.433013\n",
      "1004      30.205287  0.242061\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表分组后前3组每组的标准差为：','\\n', detailGroup.apply(np.std).head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **transform方法聚合数据**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 只有一个参数  --func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用transform将销量和售价翻倍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表的菜品销量与售价的两倍为：\n",
      "    counts  amounts\n",
      "0     2.0     98.0\n",
      "1     2.0     96.0\n",
      "2     2.0     60.0\n",
      "3     2.0     50.0\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表的菜品销量与售价的两倍为：\\n', detail[['counts','amounts']].transform(lambda x:x*2).head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 组内利差标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\Python_36\\lib\\site-packages\\ipykernel\\__main__.py:1: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表分组后实现组内离差标准化后前五行为：\n",
      "    counts   amounts\n",
      "0     NaN  0.555556\n",
      "1     NaN  0.555556\n",
      "2     NaN  0.555556\n",
      "3     NaN  0.555556\n",
      "4     NaN  0.555556\n"
     ]
    }
   ],
   "source": [
    "print('订单详情表分组后实现组内离差标准化后前五行为：\\n', detailGroup.transform(lambda x:(x.mean()-x.min())/(x.max()-x.min())).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NaN 出现是由于销量中的许多订单的最大最小值相同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **按照时间对菜品订单详情表进行拆分**\n",
    "    - 通过分组聚合将每天的数据放在一个组内，从而方便地对每个组的内容进行分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表前5组每组的数目为：\n",
      " date\n",
      "2016-08-01    217\n",
      "2016-08-02    138\n",
      "2016-08-03    157\n",
      "2016-08-04    144\n",
      "2016-08-05    193\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\Python_36\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1366, \"Incorrect string value: '\\\\xD6\\\\xD0\\\\xB9\\\\xFA\\\\xB1\\\\xEA...' for column 'VARIABLE_VALUE' at row 518\")\n",
      "  result = self._query(query)\n",
      "D:\\Program Files\\Anaconda3\\envs\\Python_36\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (3719, \"'utf8' is currently an alias for the character set UTF8MB3, which will be replaced by UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.\")\n",
      "  result = self._query(query)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('mysql+pymysql://root:123000@127.0.0.1:3306/testdb?charset=utf8')\n",
    "detail = pd.read_sql_table('meal_order_detail1',con = engine)\n",
    "detail['place_order_time'] = pd.to_datetime(detail['place_order_time'])\n",
    "detail['date'] = [i.date() for i in detail['place_order_time']]\n",
    "detailGroup = detail[['date','counts','amounts']].groupby(by='date')\n",
    "print('订单详情表前5组每组的数目为：\\n',detailGroup.size().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **使用agg方法计算单日菜品销售的平均单价和售价中位数**\n",
    "    - 对已经拆分完的订单详情进行聚合，得出每组销售均值和售价中位数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表前五组每日菜品均价为：\n",
      "               amounts\n",
      "date                 \n",
      "2016-08-01  43.161290\n",
      "2016-08-02  44.384058\n",
      "2016-08-03  43.885350\n",
      "2016-08-04  52.423611\n",
      "2016-08-05  44.927461\n"
     ]
    }
   ],
   "source": [
    "dayMean = detailGroup.agg({'amounts':np.mean})\n",
    "print('订单详情表前五组每日菜品均价为：\\n',dayMean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表前五组每日菜品售价中位数为：\n",
      "             amounts\n",
      "date               \n",
      "2016-08-01     33.0\n",
      "2016-08-02     35.0\n",
      "2016-08-03     38.0\n",
      "2016-08-04     39.0\n",
      "2016-08-05     37.0\n"
     ]
    }
   ],
   "source": [
    "dayMedian = detailGroup.agg({'amounts':np.median})\n",
    "print('订单详情表前五组每日菜品售价中位数为：\\n',dayMedian.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **使用apply方法统计单日菜品销售数目**\n",
    "    - 计算单日总销售的菜品数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表前五组每日菜品售出数目为：\n",
      " date\n",
      "2016-08-01    233.0\n",
      "2016-08-02    151.0\n",
      "2016-08-03    192.0\n",
      "2016-08-04    169.0\n",
      "2016-08-05    224.0\n",
      "Name: counts, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "daySaleSum = detailGroup.apply(np.sum)['counts']\n",
    "print('订单详情表前五组每日菜品售出数目为：\\n',daySaleSum.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建透视表与交叉表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据透视表，根据一个或多个键值对数据进行聚合，根据行或列的分组将数据划分到各个区域\n",
    "\n",
    "- **使用pivot_table函数制作菜品日销量透视表**\n",
    "- **使用crosstab函数制作菜品销量交叉表**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **使用pivot_table函数制作菜品日销量透视表**\n",
    "- `pd.pivot_table(data, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All')`\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>参数</td>\n",
    "        <td>说明</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>data</td>\n",
    "        <td>DataFrame——创建表的数据</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>values</td>\n",
    "        <td>string——聚合的数据字段名，默认全部数据</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>index</td>\n",
    "        <td>string 或 list——行分组键</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>columns</td>\n",
    "        <td>string 或 list——列分组键</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>aggfunc</td>\n",
    "        <td>functions——聚合函数，默认mean</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>margins</td>\n",
    "        <td>boolean——汇总（total）功能的开关，true==》结果集中会出现all的行和列</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>dropna</td>\n",
    "        <td>boolean——是否删掉全为NAN的列</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用订单详情制作简单透视表\n",
    "    - 订单号作为透视表的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以order_id作为分组键创建的订单透视表为：\n",
      "           amounts  counts\n",
      "order_id                 \n",
      "1002       32.000  1.0000\n",
      "1003       30.125  1.2500\n",
      "1004       43.875  1.0625\n",
      "1008       63.000  1.0000\n",
      "1011       57.700  1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\Python_36\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1366, \"Incorrect string value: '\\\\xD6\\\\xD0\\\\xB9\\\\xFA\\\\xB1\\\\xEA...' for column 'VARIABLE_VALUE' at row 518\")\n",
      "  result = self._query(query)\n",
      "D:\\Program Files\\Anaconda3\\envs\\Python_36\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (3719, \"'utf8' is currently an alias for the character set UTF8MB3, which will be replaced by UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.\")\n",
      "  result = self._query(query)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('mysql+pymysql://root:123000@127.0.0.1:3306/testdb?charset=utf8')\n",
    "detail = pd.read_sql_table('meal_order_detail1', con = engine)\n",
    "detailPivot = pd.pivot_table(detail[['order_id','counts','amounts']],index = 'order_id')\n",
    "print('以order_id作为分组键创建的订单透视表为：\\n', detailPivot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>counts</th>\n",
       "      <th>amounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>1002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>1002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>1002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>1002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>1002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>1002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>1002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     order_id  counts  amounts\n",
       "1147     1002     1.0     35.0\n",
       "1149     1002     1.0     45.0\n",
       "1150     1002     1.0     58.0\n",
       "1160     1002     1.0     30.0\n",
       "1166     1002     1.0     27.0\n",
       "1184     1002     1.0     10.0\n",
       "1189     1002     1.0     19.0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail.loc[detail['order_id']=='1002',['order_id','counts','amounts']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 可以看出，默认使用numpy.mean聚合，可通过aggfunc修改聚合函数\n",
    "- 修改聚合函数后的透视表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以order_id作为分组键创建的订单销量与售价总和透视表为：\n",
      "           amounts  counts\n",
      "order_id                 \n",
      "1002        224.0     7.0\n",
      "1003        241.0    10.0\n",
      "1004        702.0    17.0\n",
      "1008        315.0     5.0\n",
      "1011        577.0    10.0\n"
     ]
    }
   ],
   "source": [
    "detailPivot1 = pd.pivot_table(detail[[ 'order_id','counts','amounts']], index = 'order_id',aggfunc = np.sum)\n",
    "print('以order_id作为分组键创建的订单销量与售价总和透视表为：\\n', detailPivot1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 与Groupby类似，pivot_table可以分组键index可以有多个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以order_id和dishes_name作为分组键创建的订单销量与售价总和透视表为：\n",
      "                       amounts  counts\n",
      "order_id dishes_name                 \n",
      "1002     凉拌菠菜            27.0     1.0\n",
      "         南瓜枸杞小饼干         19.0     1.0\n",
      "         焖猪手             58.0     1.0\n",
      "         独家薄荷鲜虾牛肉卷       45.0     1.0\n",
      "         白胡椒胡萝卜羊肉汤       35.0     1.0\n"
     ]
    }
   ],
   "source": [
    "detailPivot2 = pd.pivot_table(detail[[ 'order_id','dishes_name', 'counts','amounts']], \n",
    "                              index = ['order_id','dishes_name'], aggfunc = np.sum)\n",
    "print('以order_id和dishes_name作为分组键创建的订单销量与售价总和透视表为：\\n',detailPivot2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 通过设置columns指定列分组，应该有两个列索引，一个是最上层的amounts和counts（数据太长，看不到），另一个是菜品名称\n",
    "- 数据不存在时，以NAN填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以order_id和dishes_name作为行列分组键创建的透视表前5行4列为：\n",
      "             amounts                        \n",
      "dishes_name  42度海之蓝  北冰洋汽水  38度剑南春  50度古井贡酒\n",
      "order_id                                   \n",
      "1002            NaN     NaN     NaN     NaN\n",
      "1003            NaN     NaN     NaN     NaN\n",
      "1004            NaN     NaN     NaN     NaN\n",
      "1008            NaN     NaN     NaN     NaN\n",
      "1011           99.0     NaN     NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "detailPivot2 = pd.pivot_table(detail[['order_id','dishes_name','counts','amounts']],\n",
    "                              index = 'order_id', \n",
    "                              columns = 'dishes_name', \n",
    "                              aggfunc = np.sum)\n",
    "print('以order_id和dishes_name作为行列分组键创建的透视表前5行4列为：\\n',detailPivot2.iloc[:5,:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 全部数据列很多时，只显示关心的列，通过指定values实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以order_id作为行分组键counts作为值创建的透视表前5行为：\n",
      "           counts\n",
      "order_id        \n",
      "1002         7.0\n",
      "1003        10.0\n",
      "1004        17.0\n",
      "1008         5.0\n",
      "1011        10.0\n"
     ]
    }
   ],
   "source": [
    "detailPivot4 = pd.pivot_table(detail[[ 'order_id','dishes_name','counts','amounts']],\n",
    "                              index = 'order_id',\n",
    "                              values = 'counts',\n",
    "                              aggfunc = np.sum)\n",
    "print('以order_id作为行分组键counts作为值创建的透视表前5行为：\\n',detailPivot4.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 不使用NAN填充，通过fill_value指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "空值填0后以order_id和dishes_name为行列分组键创建透视表前5行4列为：\n",
      "             amounts                        \n",
      "dishes_name  42度海之蓝  北冰洋汽水  38度剑南春  50度古井贡酒\n",
      "order_id                                   \n",
      "1002              0       0       0       0\n",
      "1003              0       0       0       0\n",
      "1004              0       0       0       0\n",
      "1008              0       0       0       0\n",
      "1011             99       0       0       0\n"
     ]
    }
   ],
   "source": [
    "detailPivot5 = pd.pivot_table(detail[['order_id','dishes_name','counts','amounts']],\n",
    "                              index = 'order_id',\n",
    "                              columns = 'dishes_name',\n",
    "                              aggfunc = np.sum,fill_value = 0)\n",
    "print('空值填0后以order_id和dishes_name为行列分组键创建透视表前5行4列为：\\n',detailPivot5.iloc[:5,:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 更改margins参数，查看汇总数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "添加margins后以order_id和dishes_name为分组键的透视表前5行后4列为：\n",
      "             counts                    \n",
      "dishes_name 黄油曲奇饼干 黄花菜炒木耳 黑米恋上葡萄   All\n",
      "order_id                              \n",
      "1002           0.0    0.0    0.0   7.0\n",
      "1003           0.0    0.0    0.0  10.0\n",
      "1004           0.0    1.0    0.0  17.0\n",
      "1008           0.0    0.0    0.0   5.0\n",
      "1011           0.0    0.0    0.0  10.0\n"
     ]
    }
   ],
   "source": [
    "detailPivot6 = pd.pivot_table(detail[[ 'order_id','dishes_name','counts','amounts']],\n",
    "                              index = 'order_id',\n",
    "                              columns = 'dishes_name',\n",
    "                              aggfunc = np.sum,\n",
    "                              fill_value = 0,\n",
    "                              margins = True)\n",
    "print('添加margins后以order_id和dishes_name为分组键的透视表前5行后4列为：\\n',detailPivot6.iloc[:5,-4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **crosstab创建交叉表**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 交叉表主要用于计算分组频率\n",
    "- `pd.crosstab(index, columns, values=None, rownames=None, colnames=None, aggfunc=None, margins=False, dropna=True, normalize=False)`\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>参数</td>\n",
    "        <td>说明</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>values</td>\n",
    "        <td>array——聚合数据</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>index</td>\n",
    "        <td>string 或 list——行索引键</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>columns</td>\n",
    "        <td>string 或 list——列索引键</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>rownames</td>\n",
    "        <td>行分组键名</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>colnames</td>\n",
    "        <td>列分组键名</td>\n",
    "    </tr>\n",
    "\n",
    "    <tr>\n",
    "        <td>aggfunc</td>\n",
    "        <td>functions——聚合函数，默认mean</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>margins</td>\n",
    "        <td>boolean——汇总（total）功能的开关，true==》结果集中会出现all的行和列</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>dropna</td>\n",
    "        <td>boolean——是否删掉全为NAN的列</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>normalize</td>\n",
    "        <td>boolean——是否对值进行标准化</td>\n",
    "    </tr>    \n",
    "</table>\n",
    "- 交叉表是透视表的一种，参数与pivottable基本相同，\n",
    "- crosstab中的index、columns、values，输入的都是从DataFrame中取出的某一列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以order_id和dishes_name为分组键counts为值的透视表前5行5列为：\n",
      " dishes_name   42度海之蓝   北冰洋汽水   38度剑南春   50度古井贡酒  52度泸州老窖 \n",
      "order_id                                                 \n",
      "1002             NaN      NaN      NaN      NaN       NaN\n",
      "1003             NaN      NaN      NaN      NaN       NaN\n",
      "1004             NaN      NaN      NaN      NaN       NaN\n",
      "1008             NaN      NaN      NaN      NaN       NaN\n",
      "1011             1.0      NaN      NaN      NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "detailCross = pd.crosstab(index=detail['order_id'],\n",
    "                          columns=detail['dishes_name'],\n",
    "                          values = detail['counts'],aggfunc = np.sum)\n",
    "print('以order_id和dishes_name为分组键counts为值的透视表前5行5列为：\\n',detailCross.iloc[:5,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **小任务**\n",
    "    - 创建单日菜品成交总额与总数均价透视表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 创建单日菜品成交总额与总数均价透视表\n",
    "    - 用于分析营业状况，利润"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表单日菜品成交总额与总数透视表前5行5列为：\n",
      "             amounts  counts\n",
      "date                       \n",
      "2016-08-01   9366.0   233.0\n",
      "2016-08-02   6125.0   151.0\n",
      "2016-08-03   6890.0   192.0\n",
      "2016-08-04   7549.0   169.0\n",
      "2016-08-05   8671.0   224.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\Python_36\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1366, \"Incorrect string value: '\\\\xD6\\\\xD0\\\\xB9\\\\xFA\\\\xB1\\\\xEA...' for column 'VARIABLE_VALUE' at row 518\")\n",
      "  result = self._query(query)\n",
      "D:\\Program Files\\Anaconda3\\envs\\Python_36\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (3719, \"'utf8' is currently an alias for the character set UTF8MB3, which will be replaced by UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.\")\n",
      "  result = self._query(query)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('mysql+pymysql://root:123000@127.0.0.1:3306/testdb?charset=utf8')\n",
    "detail = pd.read_sql_table('meal_order_detail1',con = engine)\n",
    "detail['place_order_time'] = pd.to_datetime(detail['place_order_time'])\n",
    "detail['date'] = [i.date() for i in detail['place_order_time']]\n",
    "PivotDetail = pd.pivot_table(detail[['date','dishes_name','counts','amounts']],\n",
    "                             index ='date',aggfunc = np.sum,\n",
    "                             margins = True)\n",
    "print('订单详情表单日菜品成交总额与总数透视表前5行5列为：\\n', PivotDetail.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 创建单个菜品单日成交总额透视表\n",
    "    - 单日成交总额对后续菜品价格调整，菜品种类调整有十分重要的作用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "订单详情表单日单个菜品成交总额交叉表后5行5列为：\n",
      " dishes_name  黄尾袋鼠西拉子红葡萄酒  黄油曲奇饼干  黄花菜炒木耳  黑米恋上葡萄       All\n",
      "date                                                      \n",
      "2016-08-07         230.0    32.0   105.0    99.0   31306.0\n",
      "2016-08-08          46.0     NaN     NaN    33.0    6532.0\n",
      "2016-08-09         138.0     NaN    35.0    99.0    7155.0\n",
      "2016-08-10          46.0     NaN    70.0    33.0   10231.0\n",
      "All                736.0    80.0   525.0   561.0  125992.0\n"
     ]
    }
   ],
   "source": [
    "CrossDetail = pd.crosstab(index=detail['date'],\n",
    "                          columns=detail['dishes_name'],\n",
    "                          values = detail['amounts'],\n",
    "                          aggfunc = np.sum,margins = True)\n",
    "print('订单详情表单日单个菜品成交总额交叉表后5行5列为：\\n',CrossDetail.iloc[-5:,-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 实训"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实训1 读取并查看P2P网络贷款数据主表的基本信息\n",
    "- 训练要点\n",
    "    - （1）掌握CSV数据读取方法。\n",
    "    - （2）掌握DataFrame的常用属性与方法。\n",
    "    - （3）掌握pandas描述性统计方法。\n",
    "- 2，需求说明\n",
    "    - P2P网络贷款主表数据主要存放了网贷用户的基本信息。探索数据的基本信息，能够洞察数据的整体分布、数据的类属关系，从而发现数据间的关联。\n",
    "- 3 实现思路及步骤\n",
    "    - （1）使用ndim、shape、memory-usage属性分别查看维度、大小、占用内存信息\n",
    "    - （2）使用describe方法进行描述性统计，并剔除值相同或全为空的列。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Training_LogInfo.csv',\n",
       " 'Training_Master.csv',\n",
       " 'Training_Userupdate.csv',\n",
       " '文件说明.xlsx']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('.\\pandas\\data_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Idx</th>\n",
       "      <th>UserInfo_1</th>\n",
       "      <th>UserInfo_2</th>\n",
       "      <th>UserInfo_3</th>\n",
       "      <th>UserInfo_4</th>\n",
       "      <th>WeblogInfo_1</th>\n",
       "      <th>WeblogInfo_2</th>\n",
       "      <th>WeblogInfo_3</th>\n",
       "      <th>WeblogInfo_4</th>\n",
       "      <th>WeblogInfo_5</th>\n",
       "      <th>...</th>\n",
       "      <th>SocialNetwork_10</th>\n",
       "      <th>SocialNetwork_11</th>\n",
       "      <th>SocialNetwork_12</th>\n",
       "      <th>SocialNetwork_13</th>\n",
       "      <th>SocialNetwork_14</th>\n",
       "      <th>SocialNetwork_15</th>\n",
       "      <th>SocialNetwork_16</th>\n",
       "      <th>SocialNetwork_17</th>\n",
       "      <th>target</th>\n",
       "      <th>ListingInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>深圳</td>\n",
       "      <td>4.0</td>\n",
       "      <td>深圳</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>222</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2014/3/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>温州</td>\n",
       "      <td>4.0</td>\n",
       "      <td>温州</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2014/2/26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>宜昌</td>\n",
       "      <td>3.0</td>\n",
       "      <td>宜昌</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014/2/28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10006</td>\n",
       "      <td>4.0</td>\n",
       "      <td>南平</td>\n",
       "      <td>1.0</td>\n",
       "      <td>南平</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014/2/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10007</td>\n",
       "      <td>5.0</td>\n",
       "      <td>辽阳</td>\n",
       "      <td>1.0</td>\n",
       "      <td>辽阳</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014/2/27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 228 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Idx  UserInfo_1 UserInfo_2  UserInfo_3 UserInfo_4  WeblogInfo_1  \\\n",
       "0  10001         1.0         深圳         4.0         深圳           NaN   \n",
       "1  10002         1.0         温州         4.0         温州           NaN   \n",
       "2  10003         1.0         宜昌         3.0         宜昌           NaN   \n",
       "3  10006         4.0         南平         1.0         南平           NaN   \n",
       "4  10007         5.0         辽阳         1.0         辽阳           NaN   \n",
       "\n",
       "   WeblogInfo_2  WeblogInfo_3  WeblogInfo_4  WeblogInfo_5     ...       \\\n",
       "0           1.0           NaN           1.0           1.0     ...        \n",
       "1           0.0           NaN           1.0           1.0     ...        \n",
       "2           0.0           NaN           2.0           2.0     ...        \n",
       "3           NaN           NaN           NaN           NaN     ...        \n",
       "4           0.0           NaN           1.0           1.0     ...        \n",
       "\n",
       "   SocialNetwork_10  SocialNetwork_11  SocialNetwork_12  SocialNetwork_13  \\\n",
       "0               222                -1                 0                 0   \n",
       "1                 1                -1                 0                 0   \n",
       "2                -1                -1                -1                 1   \n",
       "3                -1                -1                -1                 0   \n",
       "4                -1                -1                -1                 0   \n",
       "\n",
       "   SocialNetwork_14  SocialNetwork_15  SocialNetwork_16  SocialNetwork_17  \\\n",
       "0                 0                 0                 0                 1   \n",
       "1                 0                 0                 0                 2   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "   target  ListingInfo  \n",
       "0       0     2014/3/5  \n",
       "1       0    2014/2/26  \n",
       "2       0    2014/2/28  \n",
       "3       0    2014/2/25  \n",
       "4       0    2014/2/27  \n",
       "\n",
       "[5 rows x 228 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail = pd.read_csv('.\\pandas\\data_train\\Training_Master.csv', encoding='gbk')\n",
    "detail.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detail 基本信息\n",
      "*******************************\n",
      "ndim:\t 2\n",
      "***********************************************\n",
      "shape:\t (30000, 228)\n",
      "***********************************************\n",
      "size:\t 6840000\n",
      "***********************************************\n",
      "dtype:\t Idx               int64\n",
      "UserInfo_1      float64\n",
      "UserInfo_2       object\n",
      "UserInfo_3      float64\n",
      "UserInfo_4       object\n",
      "WeblogInfo_1    float64\n",
      "WeblogInfo_2    float64\n",
      "WeblogInfo_3    float64\n",
      "WeblogInfo_4    float64\n",
      "WeblogInfo_5    float64\n",
      "dtype: object\n",
      "***********************************************\n",
      "colums:\n",
      " Index(['Idx', 'UserInfo_1', 'UserInfo_2', 'UserInfo_3', 'UserInfo_4',\n",
      "       'WeblogInfo_1', 'WeblogInfo_2', 'WeblogInfo_3', 'WeblogInfo_4',\n",
      "       'WeblogInfo_5',\n",
      "       ...\n",
      "       'SocialNetwork_10', 'SocialNetwork_11', 'SocialNetwork_12',\n",
      "       'SocialNetwork_13', 'SocialNetwork_14', 'SocialNetwork_15',\n",
      "       'SocialNetwork_16', 'SocialNetwork_17', 'target', 'ListingInfo'],\n",
      "      dtype='object', length=228)\n",
      "***********************************************\n",
      "describe:\n",
      "                 Idx    UserInfo_1    UserInfo_3  WeblogInfo_1  WeblogInfo_2\n",
      "count  30000.000000  29994.000000  29993.000000    970.000000  28342.000000\n",
      "mean   46318.673267      3.219911      4.694329      2.201031      0.131466\n",
      "std    26640.397805      1.827684      1.321458      7.831679      0.358486\n",
      "min        3.000000      0.000000      0.000000      1.000000      0.000000\n",
      "25%    22924.250000      1.000000      4.000000      1.000000      0.000000\n",
      "***********************************************\n",
      "memory_usage:\n",
      " Index               80\n",
      "Idx             240000\n",
      "UserInfo_1      240000\n",
      "UserInfo_2      240000\n",
      "UserInfo_3      240000\n",
      "UserInfo_4      240000\n",
      "WeblogInfo_1    240000\n",
      "WeblogInfo_2    240000\n",
      "WeblogInfo_3    240000\n",
      "WeblogInfo_4    240000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"detail 基本信息\\n*******************************\")\n",
    "print(\"ndim:\\t\", detail.ndim)\n",
    "print(\"***********************************************\")\n",
    "print(\"shape:\\t\", detail.shape)\n",
    "print(\"***********************************************\")\n",
    "print(\"size:\\t\", detail.size)\n",
    "print(\"***********************************************\")\n",
    "print(\"dtype:\\t\", detail.dtypes[:10])\n",
    "print(\"***********************************************\")\n",
    "print(\"colums:\\n\", detail.columns)\n",
    "print(\"***********************************************\")\n",
    "print(\"describe:\\n\", detail.describe().iloc[:5,:5])\n",
    "print(\"***********************************************\")\n",
    "print(\"memory_usage:\\n\", detail.memory_usage()[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去除的列的数目为： 0\n",
      "去除后数据的形状为： (30000, 226)\n"
     ]
    }
   ],
   "source": [
    "before_len = detail.shape[1]\n",
    "std_zero = detail.describe().loc['std']==0\n",
    "col_null = detail.describe().loc['count']==0\n",
    "for i in range(len(col_null)):\n",
    "    if col_null[i]:\n",
    "        detail.drop(col_null.index[i],axis = 1,inplace=True)\n",
    "for i in range(len(std_zero)):\n",
    "    if std_zero[i]:\n",
    "        detail.drop(std_zero.index[i], axis = 1, inplace=True)\n",
    "\n",
    "after_len = detail.shape[1]\n",
    "print('去除的列的数目为：',before_len-after_len)\n",
    "print('去除后数据的形状为：',detail.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实训2提取用户信息更新表和登录信息表的时间信息\n",
    "- 1. 训练要点\n",
    "    - （1）掌握时间字符串和标准时间的转换方法。\n",
    "    - （2）掌握时间信息提取的方法。\n",
    "    - （3）掌握时间数据的算术运算。\n",
    "- 2. 需求说明\n",
    "    - 用户信息更新表和登录信息表中均存在大量的时间数据，提取时间数据内存在的信息，\n",
    "    - 一方面可以加深对数据的理解，另一方面能够探索这部分信息和目标的关联程度。\n",
    "    - 同时用户登录时间、借款成交时间、用户信息更新时间这些时间的时间差信息也能够反映出网络贷款不同用户的行为信息。\n",
    "- 3. 实现思路及步骤\n",
    "    - （1）使用to_datetime函数转换用户信息更新表和登录信息表的时间字符串。\n",
    "    - （2）使用year、month、week等方法提取用户信息更新表和登录信息表中的时间信息\n",
    "    - （3）计算用户信息更新表和登录信息表中两时间的差，分别以日、小时、分钟计算。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Training_LogInfo.csv',\n",
       " 'Training_Master.csv',\n",
       " 'Training_Userupdate.csv',\n",
       " '文件说明.xlsx']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\".\\pandas\\data_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detail_log:\n",
      "      Idx Listinginfo1  LogInfo1  LogInfo2    LogInfo3\n",
      "0  10001   2014-03-05       107         6  2014-02-20\n",
      "1  10001   2014-03-05       107         6  2014-02-23\n",
      "2  10001   2014-03-05       107         6  2014-02-24\n",
      "3  10001   2014-03-05       107         6  2014-02-25\n",
      "4  10001   2014-03-05       107         6  2014-02-27 \n",
      "************************\n",
      "detail_user:\n",
      "      Idx ListingInfo1    UserupdateInfo1 UserupdateInfo2\n",
      "0  10001   2014/03/05       _EducationId      2014/02/20\n",
      "1  10001   2014/03/05         _HasBuyCar      2014/02/20\n",
      "2  10001   2014/03/05    _LastUpdateDate      2014/02/20\n",
      "3  10001   2014/03/05  _MarriageStatusId      2014/02/20\n",
      "4  10001   2014/03/05       _MobilePhone      2014/02/20 \n",
      "************************\n"
     ]
    }
   ],
   "source": [
    "detail_user = pd.read_csv(\".\\pandas\\data_train\\Training_Userupdate.csv\", encoding='gbk')\n",
    "detail_log = pd.read_csv(\".\\pandas\\data_train\\Training_LogInfo.csv\", encoding='gbk')\n",
    "print(\"detail_log:\\n\", detail_log.head(), \"\\n************************\")\n",
    "print(\"detail_user:\\n\", detail_user.head(), \"\\n************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detail_log:\n",
      "      Idx Listinginfo1  LogInfo1  LogInfo2   LogInfo3\n",
      "0  10001   2014-03-05       107         6 2014-02-20\n",
      "1  10001   2014-03-05       107         6 2014-02-23\n",
      "2  10001   2014-03-05       107         6 2014-02-24\n",
      "3  10001   2014-03-05       107         6 2014-02-25\n",
      "4  10001   2014-03-05       107         6 2014-02-27 \n",
      "************************\n",
      "detail_user:\n",
      "      Idx ListingInfo1    UserupdateInfo1 UserupdateInfo2\n",
      "0  10001   2014-03-05       _EducationId      2014-02-20\n",
      "1  10001   2014-03-05         _HasBuyCar      2014-02-20\n",
      "2  10001   2014-03-05    _LastUpdateDate      2014-02-20\n",
      "3  10001   2014-03-05  _MarriageStatusId      2014-02-20\n",
      "4  10001   2014-03-05       _MobilePhone      2014-02-20 \n",
      "************************\n"
     ]
    }
   ],
   "source": [
    "detail_user['ListingInfo1'] = pd.to_datetime(detail_user['ListingInfo1'])\n",
    "detail_user['UserupdateInfo2'] = pd.to_datetime(detail_user['UserupdateInfo2'])\n",
    "detail_log['Listinginfo1'] = pd.to_datetime(detail_log['Listinginfo1'])\n",
    "detail_log['LogInfo3'] = pd.to_datetime(detail_log['LogInfo3'])\n",
    "print(\"detail_log:\\n\", detail_log.head(), \"\\n************************\")\n",
    "print(\"detail_user:\\n\", detail_user.head(), \"\\n************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_delta = detail_user['UserupdateInfo2'] - detail_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实训3使用分组聚合方法进一步分析用户信息更新表和登录信息表\n",
    "- 1、训练要点\n",
    "    - （1）掌握分组聚合的原理与步骤。\n",
    "    - （2）掌握agg、apply聚合方法。\n",
    "    - （3）掌握transform聚合方法。\n",
    "- 2. 需求说明\n",
    "    - 分析用户信息更新表和登录信息表时，除了提取时间本身的信息外，\n",
    "    - 还可以结合用户编号进行分组聚合，然后进行组内分析。\n",
    "    - 通过组内分析可以得出每组组内的最早和最晚信息更新时间、最早和最晚登录时间、信息更新的次数、登录的次数等信息。\n",
    "- 3 实现思路及步骤\n",
    "    - （1）使用groupby方法对用户信息更新表和登录信息表进行分组。\n",
    "    - （2）使用agg方法求取分组后的最早和最晚更新及登录时间。\n",
    "    - （3）使用size方法求取分组后的数据的信息更新次数与登录次数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实训4对用户信息更新表和登录信息表进行长宽表转换\n",
    "- 1 训练要点\n",
    "    - （1）掌握透视表的制作方法。\n",
    "    - （2）掌握交叉表的制作方法。\n",
    "- 2 需求说明\n",
    "    - 通过对数据的描述性统计，以及时间数据信息提取，分组聚合操作已经获得了相当多的信息，\n",
    "    - 但用户信息更新表和登录信息表是长表，而主表是宽表，需要通过长宽表转换将数据合并在一张以用户编号为主键的表内。\n",
    "- 3 实现思路及步骤\n",
    "    - （1）使用pivot_table函数进行长宽表转换。\n",
    "    - （2）使用crosstab方法进行长宽表转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Python_36]",
   "language": "python",
   "name": "conda-env-Python_36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
